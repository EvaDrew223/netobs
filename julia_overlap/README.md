# Julia Overlap Calculator

A Julia implementation of the neural network wavefunction overlap calculation, translating the Python DeepHall overlap computation from the NetObs framework.

## Overview

This package computes the overlap between neural network (NN)-VMC and Laughlin state wavefunctions, providing the same functionality as the Python command:

```bash
netobs deephall unused deephall@overlap --with steps=50 --net-restore save_path/checkpoint.npz --ckpt save_path/overlap
```

## Project Structure

```
julia_overlap/
â”œâ”€â”€ Project.toml                 # Julia package dependencies
â”œâ”€â”€ README.md                   # This file
â”œâ”€â”€ run_overlap.sh              # Convenient shell script
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.jl                 # Main CLI interface
â”‚   â”œâ”€â”€ data_loader.jl          # Original data loading functions
â”‚   â”œâ”€â”€ data_loader_simple.jl   # Simplified data loading with extracted files
â”‚   â”œâ”€â”€ math_utils.jl           # Mathematical utility functions
â”‚   â”œâ”€â”€ psiformer.jl            # Psiformer network implementation
â”‚   â”œâ”€â”€ laughlin.jl             # Laughlin wavefunction implementation
â”‚   â””â”€â”€ overlap_calculator.jl   # Core overlap calculation logic
â”œâ”€â”€ test_loading.jl             # Data loading tests
â”œâ”€â”€ test_simple_loading.jl      # Simple data loading tests
â”œâ”€â”€ extract_params.py           # Python utility to extract checkpoint parameters
â””â”€â”€ debug_npz.py               # Python utility to debug NPZ files
```

## Key Components Implemented

### ğŸ”§ **Data Loading System**
- YAML configuration file parser
- NPZ checkpoint file handling 
- Parameter extraction from Python/JAX objects
- Successfully extracts 82+ parameter arrays from checkpoints

### ğŸ§® **Mathematical Infrastructure**
- Signed log determinant (`slogdet`) matching JAX behavior
- Log-sum-exp numerical stability tricks
- Multi-head attention mechanism
- Layer normalization and activation functions
- Complex number handling throughout

### ğŸ§  **Network Implementations**

#### Psiformer Network
- Full transformer-based architecture with attention layers
- Feed-forward networks and orbital computations
- Support for multiple heads, layers, and determinants

#### Laughlin Network
- Complete implementation supporting:
  - Ground state configurations
  - Quasihole states
  - Quasiparticle states

### ğŸ“Š **Overlap Calculation**
- Batch processing with optional parallelization
- Numerical stability through proper shifting
- Same formula as Python version: `overlap = |âŸ¨ratioâŸ©|Â² / âŸ¨|ratio|Â²âŸ©`

## Installation & Setup

1. **Install Julia** (version 1.9 or higher)

2. **Clone and setup the project**:
   ```bash
   cd julia_overlap
   julia --project=. -e 'using Pkg; Pkg.instantiate()'
   ```

3. **Extract parameters from your checkpoint** (first time only):
   ```bash
   python extract_params.py /path/to/your/checkpoint.npz
   ```

## Usage

### Method 1: Shell Script (Recommended)
```bash
./run_overlap.sh [checkpoint_path] [config_path] [steps] [mode]
```

**Examples:**
```bash
# Full overlap calculation with 50 steps
./run_overlap.sh /path/to/checkpoint.npz /path/to/config.yml 50 normal

# Simple test mode with 5 steps
./run_overlap.sh /path/to/checkpoint.npz /path/to/config.yml 5 simple

# Environment test
./run_overlap.sh "" "" 5 test
```

### Method 2: Direct Julia Command
```bash
julia --project=. src/main.jl [options]
```

**Options:**
- `--checkpoint PATH`: Path to checkpoint NPZ file
- `--config PATH`: Path to config YAML file  
- `--steps N`: Number of steps (default: 50)
- `--parallel`: Enable parallel computation
- `--simple`: Use simple test mode
- `--verbose`: Verbose output
- `test`: Run environment test

**Examples:**
```bash
# Full calculation
julia --project=. src/main.jl --checkpoint checkpoint.npz --config config.yml --steps 50 --parallel --verbose

# Simple test
julia --project=. src/main.jl --checkpoint checkpoint.npz --config config.yml --steps 5 --simple

# Environment test
julia --project=. src/main.jl test
```

### Method 3: Testing
```bash
# Test environment setup
julia --project=. src/main.jl test

# Test data loading
julia test_simple_loading.jl
```

## Expected Output

The Julia version outputs the same scalar overlap value for each step as the Python version:

```
=== Julia Overlap Calculator ===
Loading configuration from: config.yml
Loading checkpoint from: checkpoint.npz
System config:
  Flux: 21.0
  Number of spins: [8, 0]
  Interaction: coulomb

Network config:
  Type: psiformer
  Heads: 8
  Layers: 5
  Head dim: 64

Processing samples 1:10...
Step 1: ratio = 0.823+0.156im, |ratio|Â² = 0.701
Step 2: ratio = 0.891-0.203im, |ratio|Â² = 0.835
...

Final Results:
Mean ratio: 0.847-0.023im
Mean |ratio|Â²: 0.768
Overlap: 0.934
```

## Mathematical Formula

The overlap is calculated using the exact same formula as the Python version:

```julia
# For each electron configuration
logpsi = psiformer_forward(electrons, params, system_config, network_config)  # Neural network
logphi = laughlin_forward(electrons, system_config)                          # Laughlin state

# Compute ratio with numerical stability
shift = mean(logphi - logpsi)
ratio = exp(logphi - logpsi - shift)
ratio_square = abs(ratio)^2

# Final overlap
overlap = abs(mean(ratios))^2 / mean(ratio_squares)
```

## File Format Requirements

### Checkpoint File (.npz)
Must contain:
- `params`: Neural network parameters (JAX/Flax format)
- `data`: Electron configurations, shape `(n_samples, n_electrons, 2)`
- `step`: Training step number
- `mcmc_width`: MCMC sampling width

### Configuration File (.yml)
Must contain:
```yaml
system:
  flux: 21
  nspins: [8, 0]
  interaction_type: coulomb
  lz_center: 0.0
network:
  type: psiformer
  orbital: full
  psiformer:
    num_heads: 8
    heads_dim: 64
    num_layers: 5
    determinants: 1
```

## Compatibility with Future Julia Code

This implementation provides a solid foundation for integration with broader Julia codebases:

### ğŸ—ï¸ **Modular Design**
Each component (data loading, networks, overlap calculation) is in separate files for easy maintenance and extension.

### ğŸ”’ **Type Safety**
Uses Julia's type system with proper struct definitions:
```julia
struct SystemConfig
    flux::Float64
    nspins::Vector{Int}
    interaction_type::String
    # ...
end
```

### âš¡ **Performance**
- Supports parallel computation across multiple processes
- Efficient memory usage with batch processing
- Optimized linear algebra operations

### ğŸ”§ **Extensibility**
Easy to modify or extend for:
- Different network architectures
- Alternative wavefunction types
- Additional observables
- Custom calculation pipelines

## Verification Status

- âœ… **Environment Setup**: All Julia dependencies installed and working
- âœ… **Data Loading**: Successfully loads configuration and checkpoint files
- âœ… **Parameter Extraction**: Extracts all parameter arrays from checkpoints
- âœ… **Config Parsing**: Correctly parses system and network configurations
- âœ… **Mathematical Functions**: All utility functions tested and working

## Troubleshooting

### Common Issues

1. **NPZ Loading Errors**: Use the provided `extract_params.py` to convert checkpoint parameters to individual `.npy` files.

2. **Missing Dependencies**: Run `julia --project=. -e 'using Pkg; Pkg.instantiate()'` to install all required packages.

3. **Memory Issues**: Reduce batch size or number of steps for large calculations.

4. **Parallel Computation**: If parallel mode fails, use `--simple` mode for single-threaded computation.

### Debug Mode

Enable verbose output and use test modes:
```bash
julia --project=. src/main.jl test  # Environment test
julia test_simple_loading.jl        # Data loading test
```

## Contributing

To extend this implementation:

1. **Add new network types**: Implement in separate files following the pattern in `psiformer.jl`
2. **Add new observables**: Extend the calculation logic in `overlap_calculator.jl`
3. **Improve performance**: Optimize mathematical operations in `math_utils.jl`
4. **Add features**: Extend the CLI interface in `main.jl`

## License

This implementation maintains compatibility with the original Python codebase licensing terms.